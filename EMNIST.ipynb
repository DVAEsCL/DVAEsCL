{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMNIST.ipynb",
      "provenance": [],
      "mount_file_id": "1cwGXkji3uPPRitDmD5jux3fHjhWMqBGv",
      "authorship_tag": "ABX9TyOUPNQEwTG7o3y57CGuR+d5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db70fa30330b42c3951765a80b8d723a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ee93273e8b44e70b205132d8f7f3ccc",
              "IPY_MODEL_fe01be9fbdd6415ea1f751cc490548f5"
            ],
            "layout": "IPY_MODEL_fbf07343e6a94128ac84d2705358f9af"
          }
        },
        "4ee93273e8b44e70b205132d8f7f3ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c61c38c278d49e8bcf9b3f83be10ff6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80c86984d0ec4b37994bcd7db88eb3f2",
            "value": 1
          }
        },
        "fe01be9fbdd6415ea1f751cc490548f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_156224abc2154ffa970a9af9a371204c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9889c420edac4e79b5bbb21bc476d462",
            "value": " 561758208/? [00:30&lt;00:00, 45309575.56it/s]"
          }
        },
        "fbf07343e6a94128ac84d2705358f9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c61c38c278d49e8bcf9b3f83be10ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c86984d0ec4b37994bcd7db88eb3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "156224abc2154ffa970a9af9a371204c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9889c420edac4e79b5bbb21bc476d462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DVAEsCL/DVAEsCL/blob/main/EMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr1fKWqXz1TB"
      },
      "source": [
        "#Download the EMNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "db70fa30330b42c3951765a80b8d723a",
            "4ee93273e8b44e70b205132d8f7f3ccc",
            "fe01be9fbdd6415ea1f751cc490548f5",
            "fbf07343e6a94128ac84d2705358f9af",
            "1c61c38c278d49e8bcf9b3f83be10ff6",
            "80c86984d0ec4b37994bcd7db88eb3f2",
            "156224abc2154ffa970a9af9a371204c",
            "9889c420edac4e79b5bbb21bc476d462"
          ]
        },
        "id": "_z8u8mUTplF7",
        "outputId": "cf2c419c-80bf-4286-92c2-b7a27ed8bb81"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision.datasets import EMNIST\r\n",
        "from torchvision.transforms import ToTensor\r\n",
        "from torchvision.utils import make_grid\r\n",
        "from torch.utils.data.dataloader import DataLoader\r\n",
        "from torch.utils.data import random_split\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "batch_size_train = 100000\r\n",
        "batch_size_test = 50000\r\n",
        "\r\n",
        "dataset = EMNIST(root='data/', split = 'letters', download=True, transform=torchvision.transforms.Compose([\r\n",
        "                               torchvision.transforms.ToTensor(),\r\n",
        "                               torchvision.transforms.Normalize(\r\n",
        "                                 (0.1307,), (0.3081,))\r\n",
        "                             ]))\r\n",
        "val_size = 12000\r\n",
        "train_size = len(dataset) - val_size\r\n",
        "\r\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\r\n",
        "print(len(train_ds), len(val_ds))\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size_train, shuffle=True)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size_test, shuffle=True)\r\n",
        "\r\n",
        "examples = enumerate(train_loader)\r\n",
        "batch_idx, (example_data, example_targets) = next(examples)\r\n",
        "print(example_data.shape)\r\n",
        "\r\n",
        "examples_t = enumerate(test_loader)\r\n",
        "batch_idx_t, (example_data_t, example_targets_t) = next(examples_t)\r\n",
        "print(example_data_t.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting zip archive\n",
            "Downloading http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to data/EMNIST/raw/emnist.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db70fa30330b42c3951765a80b8d723a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/EMNIST/raw/emnist.zip to data/EMNIST/raw\n",
            "Processing byclass\n",
            "Processing bymerge\n",
            "Processing balanced\n",
            "Processing letters\n",
            "Processing digits\n",
            "Processing mnist\n",
            "Done!\n",
            "112800 12000\n",
            "torch.Size([100000, 1, 28, 28])\n",
            "torch.Size([12000, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6f0tc160GnU"
      },
      "source": [
        "#If you download the zip file start from here\r\n",
        "Please download the zip file, extracts four files and upload to a drive(your_path). Please click [here](https://drive.google.com/drive/folders/1GThh-QaZeF-b6J59khdScz-XK8FeXuYy?usp=sharing) to download the data.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drgYvW34-hof"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "class encoder(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(encoder, self).__init__()\r\n",
        "    self.nc_mnist = 1\r\n",
        "    self.nc_cifar10 = 3\r\n",
        "    self.conv1 = nn.Conv2d(1, 3, 3, 1, 1) \r\n",
        "    self.conv2 = nn.Conv2d(3, 6, 2, 2, 0)\r\n",
        "    self.conv3 = nn.Conv2d(6, 12, 2, 2, 0)\r\n",
        "    self.conv4 = nn.Conv2d(12, 24, 2, 2, 0)\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.conv2(x)\r\n",
        "    x = self.conv3(x)\r\n",
        "    x = self.conv4(x)\r\n",
        "    return x\r\n",
        "class decoder(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(decoder, self).__init__()\r\n",
        "    self.nc_mnist = 118\r\n",
        "    self.nc_cifar10 = 202\r\n",
        "    self.nk_mnist = 3\r\n",
        "    self.nk_cifar10 = 4\r\n",
        "    self.decon1 = nn.ConvTranspose2d(134, 24, 3, 1, 0)\r\n",
        "    self.decon2 = nn.ConvTranspose2d(24, 12, 3, 2, 0)\r\n",
        "    self.decon3 = nn.ConvTranspose2d(12, 6, 2, 2, 0)\r\n",
        "    self.decon4 = nn.ConvTranspose2d(6, 1, 2, 2, 0)\r\n",
        "  def forward(self, x):\r\n",
        "    x = x.view(x.shape[0], 134, 1, 1)\r\n",
        "    x = self.decon1(x)\r\n",
        "    x = self.decon2(x)\r\n",
        "    x = self.decon3(x)\r\n",
        "    x = self.decon4(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "class VAE(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(VAE, self).__init__()\r\n",
        "    self.en = encoder()\r\n",
        "    self.de = decoder()\r\n",
        "    self.eps = eps\r\n",
        "    self.mnist_z = 108\r\n",
        "    self.cifar10_z = 192\r\n",
        "  def forward(self, x, one_hot):\r\n",
        "    x = self.en(x)\r\n",
        "    x = x.view(x.shape[0], -1)\r\n",
        "    mu = x[:, :108]\r\n",
        "    logvar = x[:, 108:]\r\n",
        "    std = torch.exp(0.5 * logvar)\r\n",
        "    z = mu + self.eps * std\r\n",
        "    #print(z.shape, 'aaa', one_hot.shape)\r\n",
        "    z1 = torch.cat((z, one_hot), axis = 1)\r\n",
        "    #print(z1.shape, 'bbb')\r\n",
        "    return self.de(z1), mu, logvar\r\n",
        "\r\n",
        "class private(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(private, self).__init__()\r\n",
        "    self.task = torch.nn.ModuleList()\r\n",
        "    self.eps = eps\r\n",
        "    for _ in range(13):\r\n",
        "      self.task.append(VAE(self.eps))\r\n",
        "\r\n",
        "  def forward(self, x, one_hot, task_id):\r\n",
        "    return self.task[task_id].forward(x, one_hot)\r\n",
        "\r\n",
        "class NET(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(NET, self).__init__()\r\n",
        "    self.eps = eps\r\n",
        "    self.shared = VAE(self.eps)\r\n",
        "    self.private = private(self.eps)\r\n",
        "    self.head = torch.nn.ModuleList()\r\n",
        "    self.mnist = 216\r\n",
        "    self.cifar10 = 384\r\n",
        "    self.in_mnist = 2\r\n",
        "    self.in_cifar10 = 6\r\n",
        "    for _ in range(13):\r\n",
        "      self.head.append(\r\n",
        "          nn.Sequential(\r\n",
        "            nn.Conv2d(2, 3, 3, 1, 1),\r\n",
        "            nn.Conv2d(3, 6, 2, 2, 0),\r\n",
        "            nn.Conv2d(6, 12, 2, 2, 0),\r\n",
        "            nn.Conv2d(12, 24, 2, 2, 0),\r\n",
        "            nn.Flatten(1, -1),\r\n",
        "            #nn.Linear(24*16*16, 100), #for cifar10 only\r\n",
        "            nn.Linear(216, 26)\r\n",
        "          )\r\n",
        "      )\r\n",
        "\r\n",
        "  def forward(self, x, one_hot, task_id):\r\n",
        "    s_x, s_mu, s_logvar = self.shared(x, one_hot)\r\n",
        "    p_x, p_mu, p_logvar = self.private(x, one_hot, task_id)\r\n",
        "    #print(s_x.shape, p_x.shape, '111')\r\n",
        "    x = torch.cat([s_x, p_x], dim = 1)\r\n",
        "    #print(x.shape, '22')\r\n",
        "    return self.head[task_id].forward(x), (s_x, s_mu, s_logvar), (p_x, p_mu, p_logvar)\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcMnoU3p062o"
      },
      "source": [
        "If you wish to change the number of epochs and synthetic data used as a generative replay, check lines 100 and 57, respectively. Change according to your requirments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p15kT-9-kze"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.autograd import Variable\r\n",
        "import numpy as np\r\n",
        "from collections import deque\r\n",
        "from torch.autograd import grad as torch_grad\r\n",
        "\r\n",
        "import torchvision.utils as vutils\r\n",
        "\r\n",
        "import os\r\n",
        "import os.path\r\n",
        "\r\n",
        "class CL_VAE():\r\n",
        "  def __init__(self):\r\n",
        "    super(CL_VAE, self).__init__()\r\n",
        "\r\n",
        "    self.batch_size = 64\r\n",
        "    self.mnist_z = 108\r\n",
        "    self.cifar10_z = 192\r\n",
        "    self.build_model()\r\n",
        "    self.set_cuda()\r\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\r\n",
        "    self.recon = torch.nn.MSELoss()\r\n",
        "    self.net_path = 'path/EMNIST.pth'\r\n",
        "\r\n",
        "  def build_model(self):\r\n",
        "    self.eps = torch.randn(self.batch_size, self.mnist_z)\r\n",
        "    self.eps = self.eps.cuda()\r\n",
        "    self.net = NET(self.eps)\r\n",
        "    pytorch_total_params = sum(p.numel() for p in self.net.parameters() if p.requires_grad)\r\n",
        "    print('pytorch_total_params:', pytorch_total_params)\r\n",
        "    \r\n",
        "  def set_cuda(self):\r\n",
        "    self.net.cuda()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def VAE_loss(self, recon, mu, sigma):\r\n",
        "    kl_div = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\r\n",
        "    #print('kl_div', kl_div.item())\r\n",
        "    return recon + kl_div\r\n",
        "\r\n",
        "  def train(self, all_traindata, all_trainlabels, all_testdata, all_testlabels, total_tasks):\r\n",
        "    replay_classes = []\r\n",
        "    for i in range(total_tasks):\r\n",
        "      traindata = torch.tensor(all_traindata[i])\r\n",
        "      trainlabels = torch.tensor(all_trainlabels[i])\r\n",
        "      testdata = torch.tensor(all_testdata[i])\r\n",
        "      testlabels = torch.tensor(all_testlabels[i])\r\n",
        "      #print(trainlabels, 'avfr')\r\n",
        "      replay_classes.append(sorted(list(set(trainlabels.numpy().tolist()))))\r\n",
        "      if i + 1 == 1:\r\n",
        "        self.train_task(traindata, trainlabels, testdata, testlabels, i)\r\n",
        "        #replay_classes.append(sorted(list(set(trainlabels.detach().numpy().tolist()))))\r\n",
        "      else:\r\n",
        "        num_gen_samples = 4\r\n",
        "        #z_dim = 108\r\n",
        "        for m in range(i):\r\n",
        "          #print(replay_classes, 'replay_classes')\r\n",
        "          replay_trainlabels = []\r\n",
        "          for ii in replay_classes[m]:\r\n",
        "            for j in range(num_gen_samples):\r\n",
        "              replay_trainlabels.append(ii)\r\n",
        "          replay_trainlabels = torch.tensor(replay_trainlabels)\r\n",
        "          replay_trainlabels_onehot = self.one_hot(replay_trainlabels)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "          z = torch.randn(2 * num_gen_samples, self.mnist_z)\r\n",
        "          z_one_hot = torch.cat((z, replay_trainlabels_onehot), axis = 1)\r\n",
        "          z_one_hot = z_one_hot.cuda()\r\n",
        "\r\n",
        "          replay_data = self.net.private.task[m].de(z_one_hot).detach().cpu()\r\n",
        "\r\n",
        "          traindata = torch.cat((replay_data, traindata), axis = 0)\r\n",
        "          trainlabels = torch.cat((replay_trainlabels, trainlabels))\r\n",
        "          testdata = torch.cat((testdata, torch.tensor(all_testdata[m])), axis = 0)\r\n",
        "          testlabels = torch.cat((testlabels, torch.tensor(all_testlabels[m])))\r\n",
        "        #print(sorted(list(set(testlabels.detach().numpy().tolist()))), 'aaa', i + 1)\r\n",
        "        self.train_task(traindata, trainlabels, testdata, testlabels, i)\r\n",
        "    \r\n",
        "\r\n",
        "  def one_hot(self, labels):\r\n",
        "    matrix = torch.zeros(len(labels), 26)\r\n",
        "    rows = np.arange(len(labels))\r\n",
        "    matrix[rows, labels] = 1\r\n",
        "    return matrix \r\n",
        "\r\n",
        "  def model_save(self):\r\n",
        "    torch.save(self.net.state_dict(), os.path.join(self.net_path))\r\n",
        "\r\n",
        "\r\n",
        "  def train_task(self, traindata, trainlabels, testdata, testlabels, task_id):\r\n",
        "\r\n",
        "    net_opti = torch.optim.Adam(self.net.parameters(), lr = 1e-4)\r\n",
        "    #data, label = traindata\r\n",
        "    #batch_size = 64\r\n",
        "    num_iterations = int(traindata.shape[0]/self.batch_size)\r\n",
        "    num_epochs = 50\r\n",
        "    #print(num_iterations, '451')\r\n",
        "    for e in range(num_epochs):\r\n",
        "      for i in range(num_iterations):\r\n",
        "        self.net.zero_grad()\r\n",
        "        self.net.train()\r\n",
        "        \r\n",
        "\r\n",
        "        batch_data = traindata[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        #print(batch_data.shape, '41')\r\n",
        "        batch_label = trainlabels[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        batch_label_one_hot = self.one_hot(batch_label)\r\n",
        "        batch_data = batch_data.cuda()\r\n",
        "        batch_label = batch_label.cuda()\r\n",
        "        batch_label_one_hot = batch_label_one_hot.cuda()\r\n",
        "\r\n",
        "        out, shared_out, private_out = self.net(batch_data, batch_label_one_hot, task_id)\r\n",
        "        s_x, s_mu, s_logvar = shared_out\r\n",
        "        p_x, p_mu, p_logvar = private_out\r\n",
        "        #print(out.shape, '12', batch_label.shape, s_x.shape)\r\n",
        "\r\n",
        "        cross_en_loss = self.criterion(out, batch_label)\r\n",
        "\r\n",
        "        s_recon = self.recon(batch_data, s_x)\r\n",
        "        p_recon = self.recon(batch_data, p_x)\r\n",
        "\r\n",
        "        s_VAE_loss = self.VAE_loss(s_recon, s_mu, s_logvar)\r\n",
        "        p_VAE_loss = self.VAE_loss(p_recon, p_mu, p_logvar)\r\n",
        "\r\n",
        "        all_loss = cross_en_loss + s_VAE_loss + p_VAE_loss\r\n",
        "\r\n",
        "        all_loss.backward(retain_graph=True)\r\n",
        "        net_opti.step()\r\n",
        "      #print('epoch:', e + 1, 'task_loss', cross_en_loss.item(), 's_VAE:', s_VAE_loss.item(), 'p_VAE', p_VAE_loss.item())\r\n",
        "\r\n",
        "      if (e + 1) % 25 == 0:\r\n",
        "        acc1 = self.evall(testdata, testlabels, task_id)\r\n",
        "        print('Task:', task_id + 1, 'acc', acc1)\r\n",
        "\r\n",
        "        if task_id + 1 == 13:\r\n",
        "          self.model_save()\r\n",
        "\r\n",
        "  def ev(self, test, task_id):\r\n",
        "    data, labels = test\r\n",
        "    out, _, _ = self.net(data, task_id)\r\n",
        "    pred_labels = torch.argmax(out, axis = 1)\r\n",
        "    return (torch.sum(labels == pred_labels)/data.shape[0] * 100).detach().cpu().numpy().tolist()\r\n",
        "\r\n",
        "\r\n",
        "  def evall(self, testdata, testlabels, task_id):\r\n",
        "    self.net.eval()\r\n",
        "    #data, labels = testdata\r\n",
        "    #print(testdata.shape, '11', testlabels.shape)\r\n",
        "    #batch_size = 64\r\n",
        "    num_iterations = int(testdata.shape[0]/self.batch_size)\r\n",
        "    acc = []\r\n",
        "    for i in range(num_iterations):\r\n",
        "      batch_data = testdata[i * self.batch_size : (i + 1) * self.batch_size]\r\n",
        "      batch_labels = testlabels[i * self.batch_size : (i + 1) * self.batch_size]\r\n",
        "      batch_label_one_hot = self.one_hot(batch_labels)\r\n",
        "      batch_data = batch_data.cuda()\r\n",
        "      batch_labels = batch_labels.cuda()\r\n",
        "      batch_label_one_hot = batch_label_one_hot.cuda()\r\n",
        "      out, _, _ = self.net(batch_data, batch_label_one_hot, task_id)\r\n",
        "      pred_labels = torch.argmax(out, axis = 1)\r\n",
        "      #print(pred_labels, 'aa')\r\n",
        "      #print(pred_labels.shape, '1452', batch_labels)\r\n",
        "      acc.append((torch.sum(batch_labels == pred_labels)/batch_data.shape[0] * 100).detach().cpu().numpy().tolist())\r\n",
        "    #print('acc:', acc)\r\n",
        "    return np.mean(np.array(acc))\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mFR4JzO-nRX"
      },
      "source": [
        "import json\r\n",
        "traindata_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/traindata_EMNIST.json'\r\n",
        "trainlabels_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/trainlabels_EMNIST.json'\r\n",
        "testdata_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/testdata_EMNIST.json'\r\n",
        "testlabels_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/testlabels_EMNIST.json'\r\n",
        "\r\n",
        "with open(traindata_path) as f:\r\n",
        "  traindata = json.load(f)\r\n",
        "with open(trainlabels_path) as f:\r\n",
        "  trainlabels = json.load(f)\r\n",
        "with open(testdata_path) as f:\r\n",
        "  testdata = json.load(f)\r\n",
        "with open(testlabels_path) as f:\r\n",
        "  testlabels = json.load(f)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUx0eqJr-qzO",
        "outputId": "153b780c-1571-4981-dead-2271673e2fec"
      },
      "source": [
        "import time\r\n",
        "aaa = CL_VAE()\r\n",
        "sta = time.time()\r\n",
        "aaa.train(traindata, trainlabels, testdata, testlabels, 13)\r\n",
        "end = time.time()\r\n",
        "print(\"It takes:\", end - sta)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pytorch_total_params: 562939\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}