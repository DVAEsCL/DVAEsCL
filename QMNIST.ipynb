{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QMNIST.ipynb",
      "provenance": [],
      "mount_file_id": "1VXG6O-2AamYTuWAlbPLqAt066B2N38jj",
      "authorship_tag": "ABX9TyPp7P2hN0in3mAZAd0nODf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DVAEsCL/DVAEsCL/blob/main/QMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCVFlZWl1_Y7"
      },
      "source": [
        "#Download the QMNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPq2nLpxu9Fo",
        "outputId": "c6022371-5417-4575-f136-7aa1222b69ae"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "\r\n",
        "batch_size_train = 100000\r\n",
        "batch_size_test = 50000\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "  torchvision.datasets.QMNIST('/files/', train=True, download=True,\r\n",
        "                             transform=torchvision.transforms.Compose([\r\n",
        "                               torchvision.transforms.ToTensor(),\r\n",
        "                               torchvision.transforms.Normalize(\r\n",
        "                                 (0.1307,), (0.3081,))\r\n",
        "                             ])),\r\n",
        "  batch_size=batch_size_train, shuffle=True)\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "  torchvision.datasets.QMNIST('/files/', train=False, download=True,\r\n",
        "                             transform=torchvision.transforms.Compose([\r\n",
        "                               torchvision.transforms.ToTensor(),\r\n",
        "                               torchvision.transforms.Normalize(\r\n",
        "                                 (0.1307,), (0.3081,))\r\n",
        "                             ])),\r\n",
        "  batch_size=batch_size_test, shuffle=True)\r\n",
        "\r\n",
        "examples = enumerate(train_loader)\r\n",
        "batch_idx, (example_data, example_targets) = next(examples)\r\n",
        "print(example_data.shape)\r\n",
        "\r\n",
        "examples_t = enumerate(test_loader)\r\n",
        "batch_idx_t, (example_data_t, example_targets_t) = next(examples_t)\r\n",
        "print(example_data_t.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([50000, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "LkbI5ooQygae",
        "outputId": "18790499-74df-4d5c-a282-3d622eb36a91"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "fig = plt.figure()\r\n",
        "for i in range(6):\r\n",
        "  plt.subplot(2,3,i+1)\r\n",
        "  plt.tight_layout()\r\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\r\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])\r\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Osrergymj6",
        "outputId": "d052e66b-f5f2-44e0-93f6-290e8785abdd"
      },
      "source": [
        "sorted(list(set((example_targets_t).numpy().tolist())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIqC2EMs1Ai6",
        "outputId": "ffa8ec4b-5af3-41bc-c8f1-af38d20f5007"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QMNIST.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2mSYPHg2JH-"
      },
      "source": [
        "We are converting the dataset into five tasks and storing it in some JSON files to use in the future again and again so that we do not need to download the dataset always. Later, we can extract it from the driver to train and test models when we need the data. Though, we added a link for the zip file, so please skip the first few steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4c0bHXu0ga7"
      },
      "source": [
        "def get_indices(example_targets, num_class = 100, num_task = 5):\r\n",
        "  indices_list = [[] for i in range(num_task)]\r\n",
        "\r\n",
        "  class_list = [[] for i in range(num_task)]\r\n",
        "  val = 0\r\n",
        "  for i in range(num_task):\r\n",
        "    for j in range(int(num_class/num_task)):\r\n",
        "      class_list[i].append(val + j)\r\n",
        "    val = val + j + 1\r\n",
        "\r\n",
        "  for i in range(example_targets.shape[0]):\r\n",
        "    for j in range(num_task):\r\n",
        "      if example_targets[i].item() in class_list[j]:\r\n",
        "        indices_list[j].append(i)\r\n",
        "      else:\r\n",
        "        continue\r\n",
        "  #print(class_list)\r\n",
        "  return indices_list\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK47zzOj0qEd"
      },
      "source": [
        "import json\r\n",
        "num_class = 10\r\n",
        "num_task = 5\r\n",
        "train_indices = get_indices(example_targets, num_class, num_task)\r\n",
        "test_indices = get_indices(example_targets_t, num_class, num_task)\r\n",
        "\r\n",
        "traindata_list =[]\r\n",
        "trainlabels_list = []\r\n",
        "testdata_list = []\r\n",
        "testlabels_list = []\r\n",
        "#5\r\n",
        "for j in range(num_task):\r\n",
        "  traindata = example_data[train_indices[j]]\r\n",
        "  trainlabels = example_targets[train_indices[j]]\r\n",
        "  testdata = example_data_t[test_indices[j]]\r\n",
        "  testlabels = example_targets_t[test_indices[j]]\r\n",
        "  testdata_list.append(testdata.numpy().tolist())\r\n",
        "  testlabels_list.append(testlabels.numpy().tolist())\r\n",
        "  traindata_list.append(traindata.detach().numpy().tolist())\r\n",
        "  trainlabels_list.append(trainlabels.numpy().tolist())\r\n",
        "\r\n",
        "with open('traindata_QMNIST.json', 'w') as jsonfile:\r\n",
        "    json.dump(traindata_list, jsonfile)\r\n",
        "with open('trainlabels_QMNIST.json', 'w') as jsonfile:\r\n",
        "    json.dump(trainlabels_list, jsonfile)\r\n",
        "with open('testdata_QMNIST.json', 'w') as jsonfile:\r\n",
        "    json.dump(testdata_list, jsonfile)\r\n",
        "with open('testlabels_QMNIST.json', 'w') as jsonfile:\r\n",
        "    json.dump(testlabels_list, jsonfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQF0DUqQ2P4V"
      },
      "source": [
        "#If you download the zip file start from here\r\n",
        "Please download the zip file, extracts four files and upload to a drive(your_path). Please click [here](https://drive.google.com/drive/folders/1gjhfYzBOmZ5g8wg4kq-s7ymWZKUDTXy3?usp=sharing) to download the data.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flLHYi9016RK"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "class encoder(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(encoder, self).__init__()\r\n",
        "    self.nc_mnist = 1\r\n",
        "    self.nc_cifar10 = 3\r\n",
        "    self.conv1 = nn.Conv2d(1, 3, 3, 1, 1) \r\n",
        "    self.conv2 = nn.Conv2d(3, 6, 2, 2, 0)\r\n",
        "    self.conv3 = nn.Conv2d(6, 12, 2, 2, 0)\r\n",
        "    self.conv4 = nn.Conv2d(12, 24, 2, 2, 0)\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.conv2(x)\r\n",
        "    x = self.conv3(x)\r\n",
        "    x = self.conv4(x)\r\n",
        "    return x\r\n",
        "class decoder(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(decoder, self).__init__()\r\n",
        "    self.nc_mnist = 118\r\n",
        "    self.nc_cifar10 = 202\r\n",
        "    self.nk_mnist = 3\r\n",
        "    self.nk_cifar10 = 4\r\n",
        "    self.decon1 = nn.ConvTranspose2d(118, 24, 3, 1, 0)\r\n",
        "    self.decon2 = nn.ConvTranspose2d(24, 12, 3, 2, 0)\r\n",
        "    self.decon3 = nn.ConvTranspose2d(12, 6, 2, 2, 0)\r\n",
        "    self.decon4 = nn.ConvTranspose2d(6, 1, 2, 2, 0)\r\n",
        "  def forward(self, x):\r\n",
        "    x = x.view(x.shape[0], 118, 1, 1)\r\n",
        "    x = self.decon1(x)\r\n",
        "    x = self.decon2(x)\r\n",
        "    x = self.decon3(x)\r\n",
        "    x = self.decon4(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "class VAE(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(VAE, self).__init__()\r\n",
        "    self.en = encoder()\r\n",
        "    self.de = decoder()\r\n",
        "    self.eps = eps\r\n",
        "    self.mnist_z = 108\r\n",
        "    self.cifar10_z = 192\r\n",
        "  def forward(self, x, one_hot):\r\n",
        "    x = self.en(x)\r\n",
        "    x = x.view(x.shape[0], -1)\r\n",
        "    mu = x[:, :108]\r\n",
        "    logvar = x[:, 108:]\r\n",
        "    std = torch.exp(0.5 * logvar)\r\n",
        "    z = mu + self.eps * std\r\n",
        "    #print(z.shape, 'aaa', one_hot.shape)\r\n",
        "    z1 = torch.cat((z, one_hot), axis = 1)\r\n",
        "    #print(z1.shape, 'bbb')\r\n",
        "    return self.de(z1), mu, logvar\r\n",
        "\r\n",
        "class private(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(private, self).__init__()\r\n",
        "    self.task = torch.nn.ModuleList()\r\n",
        "    self.eps = eps\r\n",
        "    for _ in range(5):\r\n",
        "      self.task.append(VAE(self.eps))\r\n",
        "\r\n",
        "  def forward(self, x, one_hot, task_id):\r\n",
        "    return self.task[task_id].forward(x, one_hot)\r\n",
        "\r\n",
        "class NET(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(NET, self).__init__()\r\n",
        "    self.eps = eps\r\n",
        "    self.shared = VAE(self.eps)\r\n",
        "    self.private = private(self.eps)\r\n",
        "    self.head = torch.nn.ModuleList()\r\n",
        "    self.mnist = 216\r\n",
        "    self.cifar10 = 384\r\n",
        "    self.in_mnist = 2\r\n",
        "    self.in_cifar10 = 6\r\n",
        "    for _ in range(5):\r\n",
        "      self.head.append(\r\n",
        "          nn.Sequential(\r\n",
        "            nn.Conv2d(2, 3, 3, 1, 1),\r\n",
        "            nn.Conv2d(3, 6, 2, 2, 0),\r\n",
        "            nn.Conv2d(6, 12, 2, 2, 0),\r\n",
        "            nn.Conv2d(12, 24, 2, 2, 0),\r\n",
        "            nn.Flatten(1, -1),\r\n",
        "            #nn.Linear(24*16*16, 100), #for cifar10 only\r\n",
        "            nn.Linear(216, 10)\r\n",
        "          )\r\n",
        "      )\r\n",
        "\r\n",
        "  def forward(self, x, one_hot, task_id):\r\n",
        "    s_x, s_mu, s_logvar = self.shared(x, one_hot)\r\n",
        "    p_x, p_mu, p_logvar = self.private(x, one_hot, task_id)\r\n",
        "    #print(s_x.shape, p_x.shape, '111')\r\n",
        "    x = torch.cat([s_x, p_x], dim = 1)\r\n",
        "    #print(x.shape, '22')\r\n",
        "    return self.head[task_id].forward(x), (s_x, s_mu, s_logvar), (p_x, p_mu, p_logvar)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSnKQxp320tl"
      },
      "source": [
        "#Number of epochs and synthetic data\r\n",
        "If you wish to change the number of epochs and synthetic data used as a generative replay, check lines 113 and 64, respectively. Change according to your requirments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcgClwBs2NVz"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.autograd import Variable\r\n",
        "import numpy as np\r\n",
        "from collections import deque\r\n",
        "from torch.autograd import grad as torch_grad\r\n",
        "\r\n",
        "import torchvision.utils as vutils\r\n",
        "\r\n",
        "import os\r\n",
        "import os.path\r\n",
        "\r\n",
        "class CL_VAE():\r\n",
        "  def __init__(self):\r\n",
        "    super(CL_VAE, self).__init__()\r\n",
        "\r\n",
        "    self.batch_size = 64\r\n",
        "    self.mnist_z = 108\r\n",
        "    self.cifar10_z = 192\r\n",
        "    self.build_model()\r\n",
        "    self.set_cuda()\r\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\r\n",
        "    self.recon = torch.nn.MSELoss()\r\n",
        "    self.net_path = 'path/QMNIST_arch.pth'\r\n",
        "    self.acc_matr = []\r\n",
        "    self.forget_mat = []\r\n",
        "    self.acc_25 = []\r\n",
        "    self.acc_50 = []\r\n",
        "    self.accuracy_matrix = [[] for kk in range(5)]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def build_model(self):\r\n",
        "    self.eps = torch.randn(self.batch_size, self.mnist_z)\r\n",
        "    self.eps = self.eps.cuda()\r\n",
        "    self.net = NET(self.eps)\r\n",
        "    pytorch_total_params = sum(p.numel() for p in self.net.parameters() if p.requires_grad)\r\n",
        "    print('pytorch_total_params:', pytorch_total_params)\r\n",
        "    \r\n",
        "  def set_cuda(self):\r\n",
        "    self.net.cuda()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def VAE_loss(self, recon, mu, sigma):\r\n",
        "    kl_div = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\r\n",
        "    #print('kl_div', kl_div.item())\r\n",
        "    return recon + kl_div\r\n",
        "\r\n",
        "  def train(self, all_traindata, all_trainlabels, all_testdata, all_testlabels, total_tasks):\r\n",
        "    replay_classes = []\r\n",
        "    for i in range(total_tasks):\r\n",
        "      traindata = torch.tensor(all_traindata[i])\r\n",
        "      trainlabels = torch.tensor(all_trainlabels[i])\r\n",
        "      testdata = torch.tensor(all_testdata[i])\r\n",
        "      testlabels = torch.tensor(all_testlabels[i])\r\n",
        "      #print(trainlabels, 'avfr')\r\n",
        "      replay_classes.append(sorted(list(set(trainlabels.numpy().tolist()))))\r\n",
        "      if i + 1 == 1:\r\n",
        "        self.train_task(traindata, trainlabels, testdata, testlabels, i)\r\n",
        "        #replay_classes.append(sorted(list(set(trainlabels.detach().numpy().tolist()))))\r\n",
        "      else:\r\n",
        "        num_gen_samples = 4\r\n",
        "        #z_dim = 108\r\n",
        "        for m in range(i):\r\n",
        "          #print(replay_classes, 'replay_classes')\r\n",
        "          replay_trainlabels = []\r\n",
        "          for ii in replay_classes[m]:\r\n",
        "            for j in range(num_gen_samples):\r\n",
        "              replay_trainlabels.append(ii)\r\n",
        "          replay_trainlabels = torch.tensor(replay_trainlabels)\r\n",
        "          replay_trainlabels_onehot = self.one_hot(replay_trainlabels)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "          z = torch.randn(2 * num_gen_samples, self.mnist_z)\r\n",
        "          z_one_hot = torch.cat((z, replay_trainlabels_onehot), axis = 1)\r\n",
        "          z_one_hot = z_one_hot.cuda()\r\n",
        "\r\n",
        "          replay_data = self.net.private.task[m].de(z_one_hot).detach().cpu()\r\n",
        "\r\n",
        "          traindata = torch.cat((replay_data, traindata), axis = 0)\r\n",
        "          trainlabels = torch.cat((replay_trainlabels, trainlabels))\r\n",
        "          testdata = torch.cat((testdata, torch.tensor(all_testdata[m])), axis = 0)\r\n",
        "          testlabels = torch.cat((testlabels, torch.tensor(all_testlabels[m])))\r\n",
        "        #print(sorted(list(set(testlabels.detach().numpy().tolist()))), 'aaa', i + 1)\r\n",
        "        self.train_task(traindata, trainlabels, testdata, testlabels, i)\r\n",
        "      self.acc_mat(all_testdata, all_testlabels, total_tasks, i)\r\n",
        "      \r\n",
        "      #print(sorted(list(set(trainlabels.detach().numpy()))), '/n', sorted(list(set(testlabels.detach().numpy()))))\r\n",
        "    self.forgetting_measure(self.accuracy_matrix, total_tasks)\r\n",
        "    #print(np.mean(np.array(self.forget_mat)), 'forget_mat:', self.forget_mat)\r\n",
        "    #print(self.acc_25, 'acc_25', np.mean(self.acc_25))\r\n",
        "    #print(self.acc_50, 'acc_50', np.mean(self.acc_50))\r\n",
        "\r\n",
        "  def one_hot(self, labels):\r\n",
        "    matrix = torch.zeros(len(labels), 10)\r\n",
        "    rows = np.arange(len(labels))\r\n",
        "    matrix[rows, labels] = 1\r\n",
        "    return matrix \r\n",
        "\r\n",
        "  def model_save(self):\r\n",
        "    torch.save(self.net.state_dict(), os.path.join(self.net_path))\r\n",
        "\r\n",
        "\r\n",
        "  def train_task(self, traindata, trainlabels, testdata, testlabels, task_id):\r\n",
        "\r\n",
        "    net_opti = torch.optim.Adam(self.net.parameters(), lr = 1e-4)\r\n",
        "    #data, label = traindata\r\n",
        "    #batch_size = 64\r\n",
        "    num_iterations = int(traindata.shape[0]/self.batch_size)\r\n",
        "    num_epochs = 2\r\n",
        "    #print(num_iterations, '451')\r\n",
        "    for e in range(num_epochs):\r\n",
        "      for i in range(num_iterations):\r\n",
        "        self.net.zero_grad()\r\n",
        "        self.net.train()\r\n",
        "        \r\n",
        "\r\n",
        "        batch_data = traindata[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        #print(batch_data.shape, '41')\r\n",
        "        batch_label = trainlabels[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        batch_label_one_hot = self.one_hot(batch_label)\r\n",
        "        batch_data = batch_data.cuda()\r\n",
        "        batch_label = batch_label.cuda()\r\n",
        "        batch_label_one_hot = batch_label_one_hot.cuda()\r\n",
        "\r\n",
        "        out, shared_out, private_out = self.net(batch_data, batch_label_one_hot, task_id)\r\n",
        "        s_x, s_mu, s_logvar = shared_out\r\n",
        "        p_x, p_mu, p_logvar = private_out\r\n",
        "        #print(out.shape, '12', batch_label.shape, s_x.shape)\r\n",
        "\r\n",
        "        cross_en_loss = self.criterion(out, batch_label)\r\n",
        "\r\n",
        "        s_recon = self.recon(batch_data, s_x)\r\n",
        "        p_recon = self.recon(batch_data, p_x)\r\n",
        "\r\n",
        "        s_VAE_loss = self.VAE_loss(s_recon, s_mu, s_logvar)\r\n",
        "        p_VAE_loss = self.VAE_loss(p_recon, p_mu, p_logvar)\r\n",
        "\r\n",
        "        all_loss = cross_en_loss + s_VAE_loss + p_VAE_loss\r\n",
        "\r\n",
        "        all_loss.backward(retain_graph=True)\r\n",
        "        net_opti.step()\r\n",
        "      #print('epoch:', e + 1, 'task_loss', cross_en_loss.item(), 's_VAE:', s_VAE_loss.item(), 'p_VAE', p_VAE_loss.item())\r\n",
        "\r\n",
        "      if (e + 1) % 2 == 0:\r\n",
        "        acc1, _ = self.evall(testdata, testlabels, task_id)\r\n",
        "\r\n",
        "        #if task_id + 1 == 5:\r\n",
        "          #self.model_save()\r\n",
        "      \r\n",
        "      if e + 1 == 25:\r\n",
        "        self.acc_25.append(acc1)\r\n",
        "      if e + 1 == 50:\r\n",
        "        self.acc_50.append(acc1)\r\n",
        "      \r\n",
        "    self.acc_matr.append(acc1)\r\n",
        "    if task_id + 1 > 1:\r\n",
        "      #print(self.acc_matr[-1], '625')\r\n",
        "      forget_measures = np.mean(self.acc_matr[-1] - np.diag(self.acc_matr))\r\n",
        "      #print(forget_mat, 'aaa', self.acc_matr[-1])\r\n",
        "      self.forget_mat.append(forget_measures)\r\n",
        "\r\n",
        "        #if task_id + 1 == 5:\r\n",
        "          #self.model_save()\r\n",
        "\r\n",
        "  def ev(self, test, task_id):\r\n",
        "    data, labels = test\r\n",
        "    out, _, _ = self.net(data, task_id)\r\n",
        "    pred_labels = torch.argmax(out, axis = 1)\r\n",
        "    return (torch.sum(labels == pred_labels)/data.shape[0] * 100).detach().cpu().numpy().tolist()\r\n",
        "\r\n",
        "\r\n",
        "  def evall(self, testdata, testlabels, task_id):\r\n",
        "    self.net.eval()\r\n",
        "\r\n",
        "    num_iterations = int(testdata.shape[0]/self.batch_size)\r\n",
        "    acc = []\r\n",
        "    pred_labels_list = []\r\n",
        "\r\n",
        "    for i in range(num_iterations):\r\n",
        "      batch_data = testdata[i * self.batch_size : (i + 1) * self.batch_size]\r\n",
        "      batch_labels = testlabels[i * self.batch_size : (i + 1) * self.batch_size]\r\n",
        "      batch_label_one_hot = self.one_hot(batch_labels)\r\n",
        "      batch_data = batch_data.cuda()\r\n",
        "      batch_labels = batch_labels.cuda()\r\n",
        "      batch_label_one_hot = batch_label_one_hot.cuda()\r\n",
        "      out, _, _ = self.net(batch_data, batch_label_one_hot, task_id)\r\n",
        "      pred_labels = torch.argmax(out, axis = 1)\r\n",
        "      #print(pred_labels, 'aa')\r\n",
        "      #print(pred_labels.shape, '1452', batch_labels)\r\n",
        "      pred_labels_list.append(pred_labels.detach().cpu().numpy().tolist())\r\n",
        "\r\n",
        "      acc.append((torch.sum(batch_labels == pred_labels)/batch_data.shape[0] * 100).detach().cpu().numpy().tolist())\r\n",
        "    #print('acc:', acc)\r\n",
        "    return np.mean(np.array(acc)), np.array(pred_labels_list).flatten()\r\n",
        "\r\n",
        "  def forgetting_measure(self, accuracy_matrix, num_tasks):\r\n",
        "    forgetting_measures = []\r\n",
        "    accuracy_matrix = np.array(accuracy_matrix)\r\n",
        "    #print(accuracy_matrix, 'aa')\r\n",
        "    for after_task_idx in range(1, num_tasks):\r\n",
        "      after_task_num = after_task_idx + 1\r\n",
        "      #print(accuracy_matrix, 'accuracy_matrix')\r\n",
        "      prev_acc = accuracy_matrix[:after_task_num - 1, :after_task_num - 1]\r\n",
        "      forgettings = prev_acc.max(axis=0) - accuracy_matrix[after_task_num - 1, :after_task_num - 1]\r\n",
        "      forgetting_measures.append(np.mean(forgettings).item())\r\n",
        "    \r\n",
        "    #print('forgetting_measures', forgetting_measures)\r\n",
        "    #print(\"the forgetting measure is...\", np.mean(np.array(forgetting_measures)))\r\n",
        "\r\n",
        "  def acc_mat(self, testData1, testLabels1, num_tasks, t):\r\n",
        "    for kk in range(num_tasks):\r\n",
        "      testData_tw = torch.tensor(testData1[kk])\r\n",
        "      testLabels_tw = torch.tensor(testLabels1[kk])\r\n",
        "      testLabels_tw_classes = sorted(list(set(testLabels_tw.detach().numpy().tolist())))\r\n",
        "      #pred_tw = (class_appr.test(testData_tw)).cpu() #classifier.predict(testData_tw)\r\n",
        "      _, pred_tw = self.evall(testData_tw, testLabels_tw, kk)\r\n",
        "      #pred_tw = torch.argmax(pred_tw, dim = 1) \r\n",
        "      #pred_tw = pred_tw.cpu()       \r\n",
        "      testLabels_tw = testLabels_tw.detach().numpy()[:pred_tw.shape[0]]\r\n",
        "      #print(pred_tw[0], '12', testLabels_tw[0])\r\n",
        "      dict_correct_tw = {}\r\n",
        "      dict_total_tw = {}\r\n",
        "\r\n",
        "      for ii in testLabels_tw_classes:\r\n",
        "        dict_total_tw[ii] = 0\r\n",
        "        dict_correct_tw[ii] = 0\r\n",
        "\r\n",
        "      for ii in range(0, testLabels_tw.shape[0]):\r\n",
        "        #print(testLabels_tw[ii],'aaa', pred_tw[ii])\r\n",
        "        if(testLabels_tw[ii] == pred_tw[ii]):\r\n",
        "          dict_correct_tw[testLabels_tw[ii].item()] = dict_correct_tw[testLabels_tw[ii].item()] + 1\r\n",
        "        #print(testLabels_tw[ii], '1', dict_total_tw[testLabels_tw[ii]], '2', dict_total_tw[testLabels_tw[ii]])\r\n",
        "        dict_total_tw[testLabels_tw[ii].item()] = dict_total_tw[testLabels_tw[ii].item()] + 1\r\n",
        "            \r\n",
        "      avgAcc_tw = 0.0\r\n",
        "      num_seen_tw = 0.0\r\n",
        "        \r\n",
        "      for ii in testLabels_tw_classes:\r\n",
        "        avgAcc_tw = avgAcc_tw + (dict_correct_tw[ii]*1.0)/(dict_total_tw[ii])\r\n",
        "        num_seen_tw = num_seen_tw + 1\r\n",
        "        \r\n",
        "      avgAcc_tw = avgAcc_tw/num_seen_tw\r\n",
        "        \r\n",
        "      #testData_tw[jj].append(avgAcc_tw)\r\n",
        "      self.accuracy_matrix[t].append(avgAcc_tw)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrK_93R52Pwb"
      },
      "source": [
        "import json\r\n",
        "traindata_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/traindata_QMNIST.json'\r\n",
        "trainlabels_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/trainlabels_QMNIST.json'\r\n",
        "testdata_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/testdata_QMNIST.json'\r\n",
        "testlabels_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/testlabels_QMNIST.json'\r\n",
        "\r\n",
        "with open(traindata_path) as f:\r\n",
        "  traindata = json.load(f)\r\n",
        "with open(trainlabels_path) as f:\r\n",
        "  trainlabels = json.load(f)\r\n",
        "with open(testdata_path) as f:\r\n",
        "  testdata = json.load(f)\r\n",
        "with open(testlabels_path) as f:\r\n",
        "  testlabels = json.load(f)\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R_ZbW-C2b77",
        "outputId": "f5c8d8e6-0e46-4e91-f164-999cddc63482"
      },
      "source": [
        "import time\r\n",
        "aaa = CL_VAE()\r\n",
        "#start = time.time()\r\n",
        "aaa.train(traindata, trainlabels, testdata, testlabels, 5)\r\n",
        "#end = time.time()\r\n",
        "#print('It took:', end - start)\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pytorch_total_params: 199019\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}