{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1enF3-fke-A9PnshQb-pQPF-TcRKjWTnm",
      "authorship_tag": "ABX9TyPRO+t0SEyEy2lePdRz4xty",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DVAEsCL/DVAEsCL/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP_LYquzCRIX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg8JI-dRCctE"
      },
      "source": [
        "#Please download the zip file\r\n",
        "Extracts four files and upload to a drive(your_path). Please click [here](https://drive.google.com/drive/folders/1KwWzKYX2ERpSbbndkWNLQZ44h19kW7UB?usp=sharing) to download the data.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0gWKiBaWYnJ"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "class encoder(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(encoder, self).__init__()\r\n",
        "    self.nc_mnist = 1\r\n",
        "    self.nc_cifar10 = 3\r\n",
        "    self.conv1 = nn.Conv2d(1, 3, 3, 1, 1) \r\n",
        "    self.conv2 = nn.Conv2d(3, 6, 2, 2, 0)\r\n",
        "    self.conv3 = nn.Conv2d(6, 12, 2, 2, 0)\r\n",
        "    self.conv4 = nn.Conv2d(12, 24, 2, 2, 0)\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.conv2(x)\r\n",
        "    x = self.conv3(x)\r\n",
        "    x = self.conv4(x)\r\n",
        "    return x\r\n",
        "class decoder(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(decoder, self).__init__()\r\n",
        "    self.nc_mnist = 118\r\n",
        "    self.nc_cifar10 = 202\r\n",
        "    self.nk_mnist = 3\r\n",
        "    self.nk_cifar10 = 4\r\n",
        "    self.decon1 = nn.ConvTranspose2d(118, 24, 3, 1, 0)\r\n",
        "    self.decon2 = nn.ConvTranspose2d(24, 12, 3, 2, 0)\r\n",
        "    self.decon3 = nn.ConvTranspose2d(12, 6, 2, 2, 0)\r\n",
        "    self.decon4 = nn.ConvTranspose2d(6, 1, 2, 2, 0)\r\n",
        "  def forward(self, x):\r\n",
        "    x = x.view(x.shape[0], 118, 1, 1)\r\n",
        "    x = self.decon1(x)\r\n",
        "    x = self.decon2(x)\r\n",
        "    x = self.decon3(x)\r\n",
        "    x = self.decon4(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "class VAE(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(VAE, self).__init__()\r\n",
        "    self.en = encoder()\r\n",
        "    self.de = decoder()\r\n",
        "    self.eps = eps\r\n",
        "    self.mnist_z = 108\r\n",
        "    self.cifar10_z = 192\r\n",
        "  def forward(self, x, one_hot):\r\n",
        "    x = self.en(x)\r\n",
        "    x = x.view(x.shape[0], -1)\r\n",
        "    mu = x[:, :108]\r\n",
        "    logvar = x[:, 108:]\r\n",
        "    std = torch.exp(0.5 * logvar)\r\n",
        "    z = mu + self.eps * std\r\n",
        "    #print(z.shape, 'aaa', one_hot.shape)\r\n",
        "    z1 = torch.cat((z, one_hot), axis = 1)\r\n",
        "    #print(z1.shape, 'bbb')\r\n",
        "    return self.de(z1), mu, logvar\r\n",
        "\r\n",
        "class private(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(private, self).__init__()\r\n",
        "    self.task = torch.nn.ModuleList()\r\n",
        "    self.eps = eps\r\n",
        "    for _ in range(5):\r\n",
        "      self.task.append(VAE(self.eps))\r\n",
        "\r\n",
        "  def forward(self, x, one_hot, task_id):\r\n",
        "    return self.task[task_id].forward(x, one_hot)\r\n",
        "\r\n",
        "class NET(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(NET, self).__init__()\r\n",
        "    self.eps = eps\r\n",
        "    self.shared = VAE(self.eps)\r\n",
        "    self.private = private(self.eps)\r\n",
        "    self.head = torch.nn.ModuleList()\r\n",
        "    self.mnist = 216\r\n",
        "    self.cifar10 = 384\r\n",
        "    self.in_mnist = 2\r\n",
        "    self.in_cifar10 = 6\r\n",
        "    for _ in range(5):\r\n",
        "      self.head.append(\r\n",
        "          nn.Sequential(\r\n",
        "            nn.Conv2d(2, 3, 3, 1, 1),\r\n",
        "            nn.Conv2d(3, 6, 2, 2, 0),\r\n",
        "            nn.Conv2d(6, 12, 2, 2, 0),\r\n",
        "            nn.Conv2d(12, 24, 2, 2, 0),\r\n",
        "            nn.Flatten(1, -1),\r\n",
        "            #nn.Linear(24*16*16, 100), #for cifar10 only\r\n",
        "            nn.Linear(216, 10)\r\n",
        "          )\r\n",
        "      )\r\n",
        "\r\n",
        "  def forward(self, x, one_hot, task_id):\r\n",
        "    s_x, s_mu, s_logvar = self.shared(x, one_hot)\r\n",
        "    p_x, p_mu, p_logvar = self.private(x, one_hot, task_id)\r\n",
        "    #print(s_x.shape, p_x.shape, '111')\r\n",
        "    x = torch.cat([s_x, p_x], dim = 1)\r\n",
        "    #print(x.shape, '22')\r\n",
        "    return self.head[task_id].forward(x), (s_x, s_mu, s_logvar), (p_x, p_mu, p_logvar)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZefPqm1FCVtW"
      },
      "source": [
        "#Number of epochs and synthetic data\r\n",
        "If you wish to change the number of epochs and synthetic data used as a generative replay, check lines 114 and 63, respectively. Change according to your requirments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKt49rRDavnu"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.autograd import Variable\r\n",
        "import numpy as np\r\n",
        "from collections import deque\r\n",
        "from torch.autograd import grad as torch_grad\r\n",
        "\r\n",
        "import torchvision.utils as vutils\r\n",
        "\r\n",
        "import os\r\n",
        "import os.path\r\n",
        "\r\n",
        "class CL_VAE():\r\n",
        "  def __init__(self):\r\n",
        "    super(CL_VAE, self).__init__()\r\n",
        "\r\n",
        "    self.batch_size = 64\r\n",
        "    self.mnist_z = 108\r\n",
        "    self.cifar10_z = 192\r\n",
        "    self.build_model()\r\n",
        "    self.set_cuda()\r\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\r\n",
        "    self.recon = torch.nn.MSELoss()\r\n",
        "    self.net_path = 'path/MNIST.pth'\r\n",
        "    self.acc_matr = []\r\n",
        "    self.forget_mat = []\r\n",
        "    self.acc_25 = []\r\n",
        "    self.acc_50 = []\r\n",
        "    self.accuracy_matrix = [[] for kk in range(5)]\r\n",
        "\r\n",
        "\r\n",
        "  def build_model(self):\r\n",
        "    self.eps = torch.randn(self.batch_size, self.mnist_z)\r\n",
        "    self.eps = self.eps.cuda()\r\n",
        "    self.net = NET(self.eps)\r\n",
        "    pytorch_total_params = sum(p.numel() for p in self.net.parameters() if p.requires_grad)\r\n",
        "    print('pytorch_total_params:', pytorch_total_params)\r\n",
        "    \r\n",
        "  def set_cuda(self):\r\n",
        "    self.net.cuda()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def VAE_loss(self, recon, mu, sigma):\r\n",
        "    kl_div = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\r\n",
        "    #print('kl_div', kl_div.item())\r\n",
        "    return recon + kl_div\r\n",
        "\r\n",
        "  def train(self, all_traindata, all_trainlabels, all_testdata, all_testlabels, total_tasks):\r\n",
        "    replay_classes = []\r\n",
        "    for i in range(total_tasks):\r\n",
        "      traindata = torch.tensor(all_traindata[i])\r\n",
        "      trainlabels = torch.tensor(all_trainlabels[i])\r\n",
        "      testdata = torch.tensor(all_testdata[i])\r\n",
        "      testlabels = torch.tensor(all_testlabels[i])\r\n",
        "      #print(trainlabels, 'avfr')\r\n",
        "      replay_classes.append(sorted(list(set(trainlabels.numpy().tolist()))))\r\n",
        "      if i + 1 == 1:\r\n",
        "        self.train_task(traindata, trainlabels, testdata, testlabels, i)\r\n",
        "        #replay_classes.append(sorted(list(set(trainlabels.detach().numpy().tolist()))))\r\n",
        "      else:\r\n",
        "        num_gen_samples = 4\r\n",
        "        #z_dim = 108\r\n",
        "        for m in range(i):\r\n",
        "          #print(replay_classes, 'replay_classes')\r\n",
        "          replay_trainlabels = []\r\n",
        "          for ii in replay_classes[m]:\r\n",
        "            for j in range(num_gen_samples):\r\n",
        "              replay_trainlabels.append(ii)\r\n",
        "          replay_trainlabels = torch.tensor(replay_trainlabels)\r\n",
        "          replay_trainlabels_onehot = self.one_hot(replay_trainlabels)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "          z = torch.randn(2 * num_gen_samples, self.mnist_z)\r\n",
        "          z_one_hot = torch.cat((z, replay_trainlabels_onehot), axis = 1)\r\n",
        "          z_one_hot = z_one_hot.cuda()\r\n",
        "\r\n",
        "          replay_data = self.net.private.task[m].de(z_one_hot).detach().cpu()\r\n",
        "\r\n",
        "          traindata = torch.cat((replay_data, traindata), axis = 0)\r\n",
        "          trainlabels = torch.cat((replay_trainlabels, trainlabels))\r\n",
        "          testdata = torch.cat((testdata, torch.tensor(all_testdata[m])), axis = 0)\r\n",
        "          testlabels = torch.cat((testlabels, torch.tensor(all_testlabels[m])))\r\n",
        "        #print(sorted(list(set(testlabels.detach().numpy().tolist()))), 'aaa', i + 1)\r\n",
        "        self.train_task(traindata, trainlabels, testdata, testlabels, i)\r\n",
        "      self.acc_mat(all_testdata, all_testlabels, total_tasks, i)\r\n",
        "      \r\n",
        "      #print(sorted(list(set(trainlabels.detach().numpy()))), '/n', sorted(list(set(testlabels.detach().numpy()))))\r\n",
        "    self.forgetting_measure(self.accuracy_matrix, total_tasks)\r\n",
        "    #print(np.mean(np.array(self.forget_mat)), 'forget_mat:', self.forget_mat)\r\n",
        "    #print(self.acc_25, 'acc_25', np.mean(self.acc_25))\r\n",
        "    #print(self.acc_50, 'acc_50', np.mean(self.acc_50))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def one_hot(self, labels):\r\n",
        "    matrix = torch.zeros(len(labels), 10)\r\n",
        "    rows = np.arange(len(labels))\r\n",
        "    matrix[rows, labels] = 1\r\n",
        "    return matrix \r\n",
        "\r\n",
        "  def model_save(self):\r\n",
        "    torch.save(self.net.state_dict(), os.path.join(self.net_path))\r\n",
        "\r\n",
        "\r\n",
        "  def train_task(self, traindata, trainlabels, testdata, testlabels, task_id):\r\n",
        "\r\n",
        "    net_opti = torch.optim.Adam(self.net.parameters(), lr = 1e-4)\r\n",
        "    #data, label = traindata\r\n",
        "    #batch_size = 64\r\n",
        "    num_iterations = int(traindata.shape[0]/self.batch_size)\r\n",
        "    num_epochs = 50\r\n",
        "    #print(num_iterations, '451')\r\n",
        "    for e in range(num_epochs):\r\n",
        "      for i in range(num_iterations):\r\n",
        "        self.net.zero_grad()\r\n",
        "        self.net.train()\r\n",
        "        \r\n",
        "\r\n",
        "        batch_data = traindata[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        #print(batch_data.shape, '41')\r\n",
        "        batch_label = trainlabels[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        batch_label_one_hot = self.one_hot(batch_label)\r\n",
        "        batch_data = batch_data.cuda()\r\n",
        "        batch_label = batch_label.cuda()\r\n",
        "        batch_label_one_hot = batch_label_one_hot.cuda()\r\n",
        "\r\n",
        "        out, shared_out, private_out = self.net(batch_data, batch_label_one_hot, task_id)\r\n",
        "        s_x, s_mu, s_logvar = shared_out\r\n",
        "        p_x, p_mu, p_logvar = private_out\r\n",
        "        #print(out.shape, '12', batch_label.shape, s_x.shape)\r\n",
        "\r\n",
        "        cross_en_loss = self.criterion(out, batch_label)\r\n",
        "\r\n",
        "        s_recon = self.recon(batch_data, s_x)\r\n",
        "        p_recon = self.recon(batch_data, p_x)\r\n",
        "\r\n",
        "        s_VAE_loss = self.VAE_loss(s_recon, s_mu, s_logvar)\r\n",
        "        p_VAE_loss = self.VAE_loss(p_recon, p_mu, p_logvar)\r\n",
        "\r\n",
        "        all_loss = cross_en_loss + s_VAE_loss + p_VAE_loss\r\n",
        "\r\n",
        "        all_loss.backward(retain_graph=True)\r\n",
        "        net_opti.step()\r\n",
        "      #print('epoch:', e + 1, 'task_loss', cross_en_loss.item(), 's_VAE:', s_VAE_loss.item(), 'p_VAE', p_VAE_loss.item())\r\n",
        "\r\n",
        "      if (e + 1) % 25 == 0:\r\n",
        "        acc1, _ = self.evall(testdata, testlabels, task_id)\r\n",
        "        a = torch.randn(self.batch_size, 1, 28, 28).cuda()\r\n",
        "        b = torch.zeros(self.batch_size).cuda()\r\n",
        "        #acc2 = self.ev((a, b), task_id)\r\n",
        "        print('Task:', task_id + 1, 'acc', acc1)\r\n",
        "\r\n",
        "        if task_id + 1 == 5:\r\n",
        "          self.model_save()\r\n",
        "      if e + 1 == 25:\r\n",
        "        self.acc_25.append(acc1)\r\n",
        "      if e + 1 == 50:\r\n",
        "        self.acc_50.append(acc1)\r\n",
        "    #self.acc_matr.append(acc1)\r\n",
        "\r\n",
        "  def ev(self, test, task_id):\r\n",
        "    data, labels = test\r\n",
        "    out, _, _ = self.net(data, task_id)\r\n",
        "    pred_labels = torch.argmax(out, axis = 1)\r\n",
        "    return (torch.sum(labels == pred_labels)/data.shape[0] * 100).detach().cpu().numpy().tolist()\r\n",
        "\r\n",
        "\r\n",
        "  def evall(self, testdata, testlabels, task_id):\r\n",
        "    self.net.eval()\r\n",
        "    #data, labels = testdata\r\n",
        "    #print(testdata.shape, '11', testlabels.shape)\r\n",
        "    #batch_size = 64\r\n",
        "    num_iterations = int(testdata.shape[0]/self.batch_size)\r\n",
        "    acc = []\r\n",
        "    pred_labels_list = []\r\n",
        "    for i in range(num_iterations):\r\n",
        "      batch_data = testdata[i * self.batch_size : (i + 1) * self.batch_size]\r\n",
        "      batch_labels = testlabels[i * self.batch_size : (i + 1) * self.batch_size]\r\n",
        "      batch_label_one_hot = self.one_hot(batch_labels)\r\n",
        "      batch_data = batch_data.cuda()\r\n",
        "      batch_labels = batch_labels.cuda()\r\n",
        "      batch_label_one_hot = batch_label_one_hot.cuda()\r\n",
        "      out, _, _ = self.net(batch_data, batch_label_one_hot, task_id)\r\n",
        "      pred_labels = torch.argmax(out, axis = 1)\r\n",
        "      #print(pred_labels, 'aa')\r\n",
        "      #print(pred_labels.shape, '1452', batch_labels)\r\n",
        "      pred_labels_list.append(pred_labels.detach().cpu().numpy().tolist())\r\n",
        "\r\n",
        "      acc.append((torch.sum(batch_labels == pred_labels)/batch_data.shape[0] * 100).detach().cpu().numpy().tolist())\r\n",
        "    #print('acc:', acc)\r\n",
        "    return np.mean(np.array(acc)), np.array(pred_labels_list).flatten()\r\n",
        "\r\n",
        "  def forgetting_measure(self, accuracy_matrix, num_tasks):\r\n",
        "    forgetting_measures = []\r\n",
        "    accuracy_matrix = np.array(accuracy_matrix)\r\n",
        "    #print(accuracy_matrix, 'aa')\r\n",
        "    for after_task_idx in range(1, num_tasks):\r\n",
        "      after_task_num = after_task_idx + 1\r\n",
        "      #print(accuracy_matrix, 'accuracy_matrix')\r\n",
        "      prev_acc = accuracy_matrix[:after_task_num - 1, :after_task_num - 1]\r\n",
        "      forgettings = prev_acc.max(axis=0) - accuracy_matrix[after_task_num - 1, :after_task_num - 1]\r\n",
        "      forgetting_measures.append(np.mean(forgettings).item())\r\n",
        "    \r\n",
        "    #print('forgetting_measures', forgetting_measures)\r\n",
        "    #print(\"the forgetting measure is...\", np.mean(np.array(forgetting_measures)))\r\n",
        "\r\n",
        "  def acc_mat(self, testData1, testLabels1, num_tasks, t):\r\n",
        "    for kk in range(num_tasks):\r\n",
        "      testData_tw = torch.tensor(testData1[kk])\r\n",
        "      testLabels_tw = torch.tensor(testLabels1[kk])\r\n",
        "      testLabels_tw_classes = sorted(list(set(testLabels_tw.detach().numpy().tolist())))\r\n",
        "      #pred_tw = (class_appr.test(testData_tw)).cpu() #classifier.predict(testData_tw)\r\n",
        "      _, pred_tw = self.evall(testData_tw, testLabels_tw, kk)\r\n",
        "      #pred_tw = torch.argmax(pred_tw, dim = 1) \r\n",
        "      #pred_tw = pred_tw.cpu()       \r\n",
        "      testLabels_tw = testLabels_tw.detach().numpy()[:pred_tw.shape[0]]\r\n",
        "      #print(pred_tw[0], '12', testLabels_tw[0])\r\n",
        "      dict_correct_tw = {}\r\n",
        "      dict_total_tw = {}\r\n",
        "\r\n",
        "      for ii in testLabels_tw_classes:\r\n",
        "        dict_total_tw[ii] = 0\r\n",
        "        dict_correct_tw[ii] = 0\r\n",
        "\r\n",
        "      for ii in range(0, testLabels_tw.shape[0]):\r\n",
        "        #print(testLabels_tw[ii],'aaa', pred_tw[ii])\r\n",
        "        if(testLabels_tw[ii] == pred_tw[ii]):\r\n",
        "          dict_correct_tw[testLabels_tw[ii].item()] = dict_correct_tw[testLabels_tw[ii].item()] + 1\r\n",
        "        #print(testLabels_tw[ii], '1', dict_total_tw[testLabels_tw[ii]], '2', dict_total_tw[testLabels_tw[ii]])\r\n",
        "        dict_total_tw[testLabels_tw[ii].item()] = dict_total_tw[testLabels_tw[ii].item()] + 1\r\n",
        "            \r\n",
        "      avgAcc_tw = 0.0\r\n",
        "      num_seen_tw = 0.0\r\n",
        "        \r\n",
        "      for ii in testLabels_tw_classes:\r\n",
        "        avgAcc_tw = avgAcc_tw + (dict_correct_tw[ii]*1.0)/(dict_total_tw[ii])\r\n",
        "        num_seen_tw = num_seen_tw + 1\r\n",
        "        \r\n",
        "      avgAcc_tw = avgAcc_tw/num_seen_tw\r\n",
        "        \r\n",
        "      #testData_tw[jj].append(avgAcc_tw)\r\n",
        "      self.accuracy_matrix[t].append(avgAcc_tw)\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKVIqFqIayhw"
      },
      "source": [
        "import json\r\n",
        "traindata_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/MNIST/traindata.json'\r\n",
        "trainlabels_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/MNIST/trainlabels.json'\r\n",
        "testdata_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/MNIST/testdata.json'\r\n",
        "testlabels_path = '/content/drive/MyDrive/ColabNotebooks/ContinualLearning/MNIST/testlabels.json'\r\n",
        "\r\n",
        "with open(traindata_path) as f:\r\n",
        "  traindata = json.load(f)\r\n",
        "with open(trainlabels_path) as f:\r\n",
        "  trainlabels = json.load(f)\r\n",
        "with open(testdata_path) as f:\r\n",
        "  testdata = json.load(f)\r\n",
        "with open(testlabels_path) as f:\r\n",
        "  testlabels = json.load(f)\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9F-YNk9a2JO",
        "outputId": "82e20a18-f4d3-49ac-9fb7-34fa6ecceff4"
      },
      "source": [
        "import time\r\n",
        "aaa = CL_VAE()\r\n",
        "start = time.time()\r\n",
        "aaa.train(traindata, trainlabels, testdata, testlabels, 5)\r\n",
        "end = time.time()\r\n",
        "#print('It took:', end - start)\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pytorch_total_params: 199019\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}